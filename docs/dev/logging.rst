PXC Log file generation
==========================

The logging facility in PXC is generated by the builtin ``logging`` python package, which greatly simplifies things.
However, given the multi-module, multiprocessed nature of the code, the implementation is a bit tortuous.

.. note:: **Quick background on the ``logging`` module**:   
    Each line (or ``record``) in a log is generated by calls to ``logger`` objects.
    These calls pass in a string message as well as a ``level`` which indicates the severity or importance of that record.
    These records are then put into files or printed to the console by objects known as ``handlers``.
    For more, see the `logging docs`_.



There are four types handler objects required: a **console** handler, a **file** handler, a **queue** handler, and a **queue** listener.
The first two types require one and only one instance: these are created and stored in the parent process, defined by ``Main.py``.
These are the only logging objects which actually have access to the "outside world" of the console and the file.

In order to pass log records between modules and processes, each chunk of code has its own queue handler object.
These handler take records and place them on a shared ``multiprocessing.Queue`` object, which is a FIFO buffer.
All of the queue handlers feed into the same queue.
The queue listener (of which there is only one, again hosted on ``Main.py``) spins off a separate daemon thread to watch the queue: each record which shows up gets popped off and passed to the file and console handlers. [#]_
I took care of the formatting by making a lightly customized subclass of ``logging.handlers.QueueListener`` called ``PXCLogger`` in the ``LogHandlers.py`` module.


PXC Logging Dev: "How Do I...?"
---------------------------------

*   If you want to log some new events, within existing modules, all you have to do is call ``logger.log()`` with the message and level.
    Alternatively, you can use the convenience functions ``logger.info()`` or ``logger.warning()``.
    As I've set it up, every piece of code executing has access to at least one logger object, sometimes as an instance variable, and sometimes with different names.  Use whichever one which has a ``logger.addHandler(logging.handlers.QueueHandler(logQ))`` call or something similar: that's the one which will propagate your record through the queue to the file.

*   If you've added a totally new module, you probably have to create a logger object with ``logging.getLogger(<name>)``, add a queue handler to it, and point it to the queue (``logQ`` in ``Main.py``.)

*   If you want to change the format of your logs, that's all within the ``PXCLogger.handle()`` function.
    I defined a few specific formats in the constructor, and then used them when the record gets handled based on the name of the logger object which generated that record.



.. [#] If you've never come across queues in programming before, think of it as several tubes (queue handlers) each pouring a stream of marbles (``records``) into a funnel (the queue listener). Only one marble can come out of the funnel at a time, and we have very little control over the order in which they go through, but they all get through eventually.



.. _`logging docs`: https://docs.python.org/3/library/logging.html